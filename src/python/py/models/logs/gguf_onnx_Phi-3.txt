C:\llama.cpp\Onnx-GenAI\src\python\py\models>e:\xCloud_Reuse\python312\python.exe builder.py -m microsoft/phi-3-mini-4k-instruct -e cpu --extra_options xx_xxxxx="xx_xxxxxxxxxxxxxxxxxxxxxxx" -c c:\llama.cpp\models\Phi-3\microsoft-Phi-3 -o e:\llama.cpp\models\Phi-3\onnx\gguf_onnx -p int4 -i c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-fp32-LMStudio.gguf
Valid precision + execution provider combinations are: FP32 CPU, FP32 CUDA, FP16 CUDA, FP16 DML, INT4 CPU, INT4 CUDA, INT4 DML
Extra options: {'xx_xxxxx': 'xx_xxxxxxxxxxxxxxxxxxxxxxxxxx'}
GroupQueryAttention (GQA) is used in this model.
Reading embedding layer
Reading decoder layer 0
Reading decoder layer 1
Reading decoder layer 2
Reading decoder layer 3
Reading decoder layer 4
Reading decoder layer 5
Reading decoder layer 6
Reading decoder layer 7
Reading decoder layer 8
Reading decoder layer 9
Reading decoder layer 10
Reading decoder layer 11
Reading decoder layer 12
Reading decoder layer 13
Reading decoder layer 14
Reading decoder layer 15
Reading decoder layer 16
Reading decoder layer 17
Reading decoder layer 18
Reading decoder layer 19
Reading decoder layer 20
Reading decoder layer 21
Reading decoder layer 22
Reading decoder layer 23
Reading decoder layer 24
Reading decoder layer 25
Reading decoder layer 26
Reading decoder layer 27
Reading decoder layer 28
Reading decoder layer 29
Reading decoder layer 30
Reading decoder layer 31
Reading final norm
Reading LM head
Saving ONNX model in e:\llama.cpp\models\Phi-3\onnx\gguf_onnx
2025-02-08 02:08:18,952 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/constant_nodes/TensorProto.INT64/1D/1 ...
2025-02-08 02:08:18,952 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/attn_mask_reformat/attn_mask_subgraph/ReduceSum ...
2025-02-08 02:08:18,952 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/attn_mask_reformat/attn_mask_subgraph/Sub ...
2025-02-08 02:08:18,952 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/attn_mask_reformat/attn_mask_subgraph/Sub/Cast ...
2025-02-08 02:08:18,952 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/attn_mask_reformat/attn_mask_subgraph/Shape ...
2025-02-08 02:08:18,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/constant_nodes/TensorProto.INT64/0D/1 ...
2025-02-08 02:08:18,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/attn_mask_reformat/attn_mask_subgraph/Gather ...
2025-02-08 02:08:18,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/attn_mask_reformat/attn_mask_subgraph/Gather/Cast ...
2025-02-08 02:08:18,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/embed_tokens/Gather ...
2025-02-08 02:08:18,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.0/input_layernorm/LayerNorm ...
2025-02-08 02:08:18,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/attn/qkv_proj/MatMul ...
2025-02-08 02:08:19,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/attn/qkv_proj/MatMul ...
2025-02-08 02:08:19,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.0/attn/GroupQueryAttention ...
2025-02-08 02:08:19,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/attn/o_proj/MatMul ...
2025-02-08 02:08:19,117 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/attn/o_proj/MatMul ...
2025-02-08 02:08:19,117 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.0/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:19,117 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/mlp/gate_proj/MatMul ...
2025-02-08 02:08:19,258 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/mlp/gate_proj/MatMul ...
2025-02-08 02:08:19,258 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/mlp/up_proj/MatMul ...
2025-02-08 02:08:19,401 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/mlp/up_proj/MatMul ...
2025-02-08 02:08:19,401 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.0/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:19,401 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.0/mlp/act_fn/Mul ...
2025-02-08 02:08:19,401 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.0/mlp/Mul ...
2025-02-08 02:08:19,402 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/mlp/down_proj/MatMul ...
2025-02-08 02:08:19,499 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/mlp/down_proj/MatMul ...
2025-02-08 02:08:19,499 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.1/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:19,499 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/attn/qkv_proj/MatMul ...
2025-02-08 02:08:19,625 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/attn/qkv_proj/MatMul ...
2025-02-08 02:08:19,625 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.1/attn/GroupQueryAttention ...
2025-02-08 02:08:19,626 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/attn/o_proj/MatMul ...
2025-02-08 02:08:19,679 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/attn/o_proj/MatMul ...
2025-02-08 02:08:19,679 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.1/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:19,679 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/mlp/gate_proj/MatMul ...
2025-02-08 02:08:19,857 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/mlp/gate_proj/MatMul ...
2025-02-08 02:08:19,858 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/mlp/up_proj/MatMul ...
2025-02-08 02:08:20,031 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/mlp/up_proj/MatMul ...
2025-02-08 02:08:20,031 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.1/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:20,031 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.1/mlp/act_fn/Mul ...
2025-02-08 02:08:20,032 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.1/mlp/Mul ...
2025-02-08 02:08:20,032 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/mlp/down_proj/MatMul ...
2025-02-08 02:08:20,363 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/mlp/down_proj/MatMul ...
2025-02-08 02:08:20,363 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.2/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:20,363 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/attn/qkv_proj/MatMul ...
2025-02-08 02:08:20,832 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/attn/qkv_proj/MatMul ...
2025-02-08 02:08:20,832 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.2/attn/GroupQueryAttention ...
2025-02-08 02:08:20,833 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/attn/o_proj/MatMul ...
2025-02-08 02:08:20,884 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/attn/o_proj/MatMul ...
2025-02-08 02:08:20,884 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.2/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:20,884 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/mlp/gate_proj/MatMul ...
2025-02-08 02:08:21,064 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/mlp/gate_proj/MatMul ...
2025-02-08 02:08:21,064 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/mlp/up_proj/MatMul ...
2025-02-08 02:08:21,224 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/mlp/up_proj/MatMul ...
2025-02-08 02:08:21,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.2/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:21,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.2/mlp/act_fn/Mul ...
2025-02-08 02:08:21,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.2/mlp/Mul ...
2025-02-08 02:08:21,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/mlp/down_proj/MatMul ...
2025-02-08 02:08:21,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/mlp/down_proj/MatMul ...
2025-02-08 02:08:21,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.3/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:21,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/attn/qkv_proj/MatMul ...
2025-02-08 02:08:21,491 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/attn/qkv_proj/MatMul ...
2025-02-08 02:08:21,492 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.3/attn/GroupQueryAttention ...
2025-02-08 02:08:21,492 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/attn/o_proj/MatMul ...
2025-02-08 02:08:21,542 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/attn/o_proj/MatMul ...
2025-02-08 02:08:21,543 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.3/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:21,543 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/mlp/gate_proj/MatMul ...
2025-02-08 02:08:21,734 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/mlp/gate_proj/MatMul ...
2025-02-08 02:08:21,735 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/mlp/up_proj/MatMul ...
2025-02-08 02:08:21,907 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/mlp/up_proj/MatMul ...
2025-02-08 02:08:21,908 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.3/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:21,908 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.3/mlp/act_fn/Mul ...
2025-02-08 02:08:21,908 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.3/mlp/Mul ...
2025-02-08 02:08:21,908 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/mlp/down_proj/MatMul ...
2025-02-08 02:08:22,037 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/mlp/down_proj/MatMul ...
2025-02-08 02:08:22,037 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.4/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:22,037 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/attn/qkv_proj/MatMul ...
2025-02-08 02:08:22,168 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/attn/qkv_proj/MatMul ...
2025-02-08 02:08:22,169 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.4/attn/GroupQueryAttention ...
2025-02-08 02:08:22,169 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/attn/o_proj/MatMul ...
2025-02-08 02:08:22,219 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/attn/o_proj/MatMul ...
2025-02-08 02:08:22,220 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.4/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:22,220 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/mlp/gate_proj/MatMul ...
2025-02-08 02:08:22,381 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/mlp/gate_proj/MatMul ...
2025-02-08 02:08:22,381 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/mlp/up_proj/MatMul ...
2025-02-08 02:08:22,553 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/mlp/up_proj/MatMul ...
2025-02-08 02:08:22,553 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.4/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:22,553 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.4/mlp/act_fn/Mul ...
2025-02-08 02:08:22,554 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.4/mlp/Mul ...
2025-02-08 02:08:22,554 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/mlp/down_proj/MatMul ...
2025-02-08 02:08:22,688 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/mlp/down_proj/MatMul ...
2025-02-08 02:08:22,688 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.5/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:22,688 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/attn/qkv_proj/MatMul ...
2025-02-08 02:08:22,836 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/attn/qkv_proj/MatMul ...
2025-02-08 02:08:22,837 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.5/attn/GroupQueryAttention ...
2025-02-08 02:08:22,837 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/attn/o_proj/MatMul ...
2025-02-08 02:08:22,871 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/attn/o_proj/MatMul ...
2025-02-08 02:08:22,871 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.5/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:22,872 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/mlp/gate_proj/MatMul ...
2025-02-08 02:08:22,993 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/mlp/gate_proj/MatMul ...
2025-02-08 02:08:22,993 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/mlp/up_proj/MatMul ...
2025-02-08 02:08:23,119 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/mlp/up_proj/MatMul ...
2025-02-08 02:08:23,119 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.5/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:23,119 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.5/mlp/act_fn/Mul ...
2025-02-08 02:08:23,120 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.5/mlp/Mul ...
2025-02-08 02:08:23,120 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/mlp/down_proj/MatMul ...
2025-02-08 02:08:23,215 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/mlp/down_proj/MatMul ...
2025-02-08 02:08:23,216 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.6/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:23,216 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/attn/qkv_proj/MatMul ...
2025-02-08 02:08:23,317 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/attn/qkv_proj/MatMul ...
2025-02-08 02:08:23,318 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.6/attn/GroupQueryAttention ...
2025-02-08 02:08:23,318 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/attn/o_proj/MatMul ...
2025-02-08 02:08:23,359 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/attn/o_proj/MatMul ...
2025-02-08 02:08:23,359 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.6/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:23,359 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/mlp/gate_proj/MatMul ...
2025-02-08 02:08:23,480 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/mlp/gate_proj/MatMul ...
2025-02-08 02:08:23,480 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/mlp/up_proj/MatMul ...
2025-02-08 02:08:23,617 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/mlp/up_proj/MatMul ...
2025-02-08 02:08:23,617 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.6/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:23,618 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.6/mlp/act_fn/Mul ...
2025-02-08 02:08:23,618 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.6/mlp/Mul ...
2025-02-08 02:08:23,618 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/mlp/down_proj/MatMul ...
2025-02-08 02:08:23,717 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/mlp/down_proj/MatMul ...
2025-02-08 02:08:23,718 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.7/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:23,718 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/attn/qkv_proj/MatMul ...
2025-02-08 02:08:23,830 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/attn/qkv_proj/MatMul ...
2025-02-08 02:08:23,830 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.7/attn/GroupQueryAttention ...
2025-02-08 02:08:23,830 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/attn/o_proj/MatMul ...
2025-02-08 02:08:23,864 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/attn/o_proj/MatMul ...
2025-02-08 02:08:23,864 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.7/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:23,864 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/mlp/gate_proj/MatMul ...
2025-02-08 02:08:23,983 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/mlp/gate_proj/MatMul ...
2025-02-08 02:08:23,983 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/mlp/up_proj/MatMul ...
2025-02-08 02:08:24,114 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/mlp/up_proj/MatMul ...
2025-02-08 02:08:24,114 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.7/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:24,114 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.7/mlp/act_fn/Mul ...
2025-02-08 02:08:24,114 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.7/mlp/Mul ...
2025-02-08 02:08:24,115 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/mlp/down_proj/MatMul ...
2025-02-08 02:08:24,208 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/mlp/down_proj/MatMul ...
2025-02-08 02:08:24,209 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.8/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:24,209 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/attn/qkv_proj/MatMul ...
2025-02-08 02:08:24,312 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/attn/qkv_proj/MatMul ...
2025-02-08 02:08:24,312 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.8/attn/GroupQueryAttention ...
2025-02-08 02:08:24,312 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/attn/o_proj/MatMul ...
2025-02-08 02:08:24,350 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/attn/o_proj/MatMul ...
2025-02-08 02:08:24,350 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.8/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:24,350 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/mlp/gate_proj/MatMul ...
2025-02-08 02:08:24,608 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/mlp/gate_proj/MatMul ...
2025-02-08 02:08:24,608 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/mlp/up_proj/MatMul ...
2025-02-08 02:08:24,731 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/mlp/up_proj/MatMul ...
2025-02-08 02:08:24,733 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.8/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:24,733 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.8/mlp/act_fn/Mul ...
2025-02-08 02:08:24,733 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.8/mlp/Mul ...
2025-02-08 02:08:24,733 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/mlp/down_proj/MatMul ...
2025-02-08 02:08:24,833 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/mlp/down_proj/MatMul ...
2025-02-08 02:08:24,834 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.9/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:24,834 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/attn/qkv_proj/MatMul ...
2025-02-08 02:08:24,938 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/attn/qkv_proj/MatMul ...
2025-02-08 02:08:24,939 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.9/attn/GroupQueryAttention ...
2025-02-08 02:08:24,939 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/attn/o_proj/MatMul ...
2025-02-08 02:08:24,976 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/attn/o_proj/MatMul ...
2025-02-08 02:08:24,976 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.9/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:24,976 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/mlp/gate_proj/MatMul ...
2025-02-08 02:08:25,104 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/mlp/gate_proj/MatMul ...
2025-02-08 02:08:25,105 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/mlp/up_proj/MatMul ...
2025-02-08 02:08:25,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/mlp/up_proj/MatMul ...
2025-02-08 02:08:25,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.9/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:25,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.9/mlp/act_fn/Mul ...
2025-02-08 02:08:25,225 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.9/mlp/Mul ...
2025-02-08 02:08:25,226 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/mlp/down_proj/MatMul ...
2025-02-08 02:08:25,318 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/mlp/down_proj/MatMul ...
2025-02-08 02:08:25,318 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.10/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:25,318 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/attn/qkv_proj/MatMul ...
2025-02-08 02:08:25,422 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/attn/qkv_proj/MatMul ...
2025-02-08 02:08:25,423 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.10/attn/GroupQueryAttention ...
2025-02-08 02:08:25,423 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/attn/o_proj/MatMul ...
2025-02-08 02:08:25,456 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/attn/o_proj/MatMul ...
2025-02-08 02:08:25,457 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.10/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:25,457 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/mlp/gate_proj/MatMul ...
2025-02-08 02:08:25,677 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/mlp/gate_proj/MatMul ...
2025-02-08 02:08:25,677 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/mlp/up_proj/MatMul ...
2025-02-08 02:08:25,806 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/mlp/up_proj/MatMul ...
2025-02-08 02:08:25,807 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.10/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:25,807 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.10/mlp/act_fn/Mul ...
2025-02-08 02:08:25,807 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.10/mlp/Mul ...
2025-02-08 02:08:25,807 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/mlp/down_proj/MatMul ...
2025-02-08 02:08:25,913 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/mlp/down_proj/MatMul ...
2025-02-08 02:08:25,913 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.11/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:25,914 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/attn/qkv_proj/MatMul ...
2025-02-08 02:08:26,024 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/attn/qkv_proj/MatMul ...
2025-02-08 02:08:26,024 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.11/attn/GroupQueryAttention ...
2025-02-08 02:08:26,024 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/attn/o_proj/MatMul ...
2025-02-08 02:08:26,059 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/attn/o_proj/MatMul ...
2025-02-08 02:08:26,059 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.11/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:26,059 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/mlp/gate_proj/MatMul ...
2025-02-08 02:08:26,180 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/mlp/gate_proj/MatMul ...
2025-02-08 02:08:26,181 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/mlp/up_proj/MatMul ...
2025-02-08 02:08:26,313 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/mlp/up_proj/MatMul ...
2025-02-08 02:08:26,313 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.11/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:26,313 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.11/mlp/act_fn/Mul ...
2025-02-08 02:08:26,313 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.11/mlp/Mul ...
2025-02-08 02:08:26,313 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/mlp/down_proj/MatMul ...
2025-02-08 02:08:26,410 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/mlp/down_proj/MatMul ...
2025-02-08 02:08:26,410 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.12/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:26,410 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/attn/qkv_proj/MatMul ...
2025-02-08 02:08:26,515 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/attn/qkv_proj/MatMul ...
2025-02-08 02:08:26,515 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.12/attn/GroupQueryAttention ...
2025-02-08 02:08:26,515 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/attn/o_proj/MatMul ...
2025-02-08 02:08:26,556 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/attn/o_proj/MatMul ...
2025-02-08 02:08:26,556 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.12/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:26,556 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/mlp/gate_proj/MatMul ...
2025-02-08 02:08:26,704 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/mlp/gate_proj/MatMul ...
2025-02-08 02:08:26,704 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/mlp/up_proj/MatMul ...
2025-02-08 02:08:26,855 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/mlp/up_proj/MatMul ...
2025-02-08 02:08:26,855 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.12/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:26,855 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.12/mlp/act_fn/Mul ...
2025-02-08 02:08:26,855 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.12/mlp/Mul ...
2025-02-08 02:08:26,855 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/mlp/down_proj/MatMul ...
2025-02-08 02:08:26,950 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/mlp/down_proj/MatMul ...
2025-02-08 02:08:26,950 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.13/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:26,950 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/attn/qkv_proj/MatMul ...
2025-02-08 02:08:27,052 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/attn/qkv_proj/MatMul ...
2025-02-08 02:08:27,052 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.13/attn/GroupQueryAttention ...
2025-02-08 02:08:27,052 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/attn/o_proj/MatMul ...
2025-02-08 02:08:27,093 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/attn/o_proj/MatMul ...
2025-02-08 02:08:27,093 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.13/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:27,093 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/mlp/gate_proj/MatMul ...
2025-02-08 02:08:27,215 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/mlp/gate_proj/MatMul ...
2025-02-08 02:08:27,216 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/mlp/up_proj/MatMul ...
2025-02-08 02:08:27,574 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/mlp/up_proj/MatMul ...
2025-02-08 02:08:27,575 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.13/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:27,575 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.13/mlp/act_fn/Mul ...
2025-02-08 02:08:27,575 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.13/mlp/Mul ...
2025-02-08 02:08:27,575 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/mlp/down_proj/MatMul ...
2025-02-08 02:08:27,678 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/mlp/down_proj/MatMul ...
2025-02-08 02:08:27,678 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.14/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:27,679 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/attn/qkv_proj/MatMul ...
2025-02-08 02:08:27,791 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/attn/qkv_proj/MatMul ...
2025-02-08 02:08:27,791 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.14/attn/GroupQueryAttention ...
2025-02-08 02:08:27,791 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/attn/o_proj/MatMul ...
2025-02-08 02:08:27,838 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/attn/o_proj/MatMul ...
2025-02-08 02:08:27,838 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.14/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:27,839 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/mlp/gate_proj/MatMul ...
2025-02-08 02:08:27,984 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/mlp/gate_proj/MatMul ...
2025-02-08 02:08:27,984 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/mlp/up_proj/MatMul ...
2025-02-08 02:08:28,137 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/mlp/up_proj/MatMul ...
2025-02-08 02:08:28,137 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.14/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:28,137 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.14/mlp/act_fn/Mul ...
2025-02-08 02:08:28,137 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.14/mlp/Mul ...
2025-02-08 02:08:28,138 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/mlp/down_proj/MatMul ...
2025-02-08 02:08:28,252 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/mlp/down_proj/MatMul ...
2025-02-08 02:08:28,252 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.15/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:28,252 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/attn/qkv_proj/MatMul ...
2025-02-08 02:08:28,369 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/attn/qkv_proj/MatMul ...
2025-02-08 02:08:28,369 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.15/attn/GroupQueryAttention ...
2025-02-08 02:08:28,369 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/attn/o_proj/MatMul ...
2025-02-08 02:08:28,914 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/attn/o_proj/MatMul ...
2025-02-08 02:08:28,914 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.15/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:28,914 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/mlp/gate_proj/MatMul ...
2025-02-08 02:08:29,043 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/mlp/gate_proj/MatMul ...
2025-02-08 02:08:29,043 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/mlp/up_proj/MatMul ...
2025-02-08 02:08:29,172 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/mlp/up_proj/MatMul ...
2025-02-08 02:08:29,172 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.15/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:29,172 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.15/mlp/act_fn/Mul ...
2025-02-08 02:08:29,172 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.15/mlp/Mul ...
2025-02-08 02:08:29,173 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/mlp/down_proj/MatMul ...
2025-02-08 02:08:29,271 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/mlp/down_proj/MatMul ...
2025-02-08 02:08:29,272 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.16/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:29,272 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/attn/qkv_proj/MatMul ...
2025-02-08 02:08:29,380 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/attn/qkv_proj/MatMul ...
2025-02-08 02:08:29,381 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.16/attn/GroupQueryAttention ...
2025-02-08 02:08:29,381 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/attn/o_proj/MatMul ...
2025-02-08 02:08:29,423 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/attn/o_proj/MatMul ...
2025-02-08 02:08:29,424 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.16/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:29,424 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/mlp/gate_proj/MatMul ...
2025-02-08 02:08:29,557 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/mlp/gate_proj/MatMul ...
2025-02-08 02:08:29,557 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/mlp/up_proj/MatMul ...
2025-02-08 02:08:29,699 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/mlp/up_proj/MatMul ...
2025-02-08 02:08:29,700 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.16/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:29,700 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.16/mlp/act_fn/Mul ...
2025-02-08 02:08:29,700 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.16/mlp/Mul ...
2025-02-08 02:08:29,700 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/mlp/down_proj/MatMul ...
2025-02-08 02:08:29,809 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/mlp/down_proj/MatMul ...
2025-02-08 02:08:29,810 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.17/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:29,810 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/attn/qkv_proj/MatMul ...
2025-02-08 02:08:29,916 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/attn/qkv_proj/MatMul ...
2025-02-08 02:08:29,917 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.17/attn/GroupQueryAttention ...
2025-02-08 02:08:29,917 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/attn/o_proj/MatMul ...
2025-02-08 02:08:29,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/attn/o_proj/MatMul ...
2025-02-08 02:08:29,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.17/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:29,954 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/mlp/gate_proj/MatMul ...
2025-02-08 02:08:30,083 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/mlp/gate_proj/MatMul ...
2025-02-08 02:08:30,084 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/mlp/up_proj/MatMul ...
2025-02-08 02:08:30,207 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/mlp/up_proj/MatMul ...
2025-02-08 02:08:30,208 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.17/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:30,208 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.17/mlp/act_fn/Mul ...
2025-02-08 02:08:30,208 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.17/mlp/Mul ...
2025-02-08 02:08:30,208 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/mlp/down_proj/MatMul ...
2025-02-08 02:08:30,304 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/mlp/down_proj/MatMul ...
2025-02-08 02:08:30,304 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.18/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:30,304 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/attn/qkv_proj/MatMul ...
2025-02-08 02:08:30,418 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/attn/qkv_proj/MatMul ...
2025-02-08 02:08:30,418 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.18/attn/GroupQueryAttention ...
2025-02-08 02:08:30,418 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/attn/o_proj/MatMul ...
2025-02-08 02:08:30,457 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/attn/o_proj/MatMul ...
2025-02-08 02:08:30,457 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.18/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:30,458 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/mlp/gate_proj/MatMul ...
2025-02-08 02:08:30,598 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/mlp/gate_proj/MatMul ...
2025-02-08 02:08:30,599 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/mlp/up_proj/MatMul ...
2025-02-08 02:08:30,742 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/mlp/up_proj/MatMul ...
2025-02-08 02:08:30,742 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.18/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:30,743 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.18/mlp/act_fn/Mul ...
2025-02-08 02:08:30,743 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.18/mlp/Mul ...
2025-02-08 02:08:30,743 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/mlp/down_proj/MatMul ...
2025-02-08 02:08:30,844 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/mlp/down_proj/MatMul ...
2025-02-08 02:08:30,844 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.19/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:30,844 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/attn/qkv_proj/MatMul ...
2025-02-08 02:08:30,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/attn/qkv_proj/MatMul ...
2025-02-08 02:08:30,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.19/attn/GroupQueryAttention ...
2025-02-08 02:08:30,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/attn/o_proj/MatMul ...
2025-02-08 02:08:30,994 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/attn/o_proj/MatMul ...
2025-02-08 02:08:30,994 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.19/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:30,994 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/mlp/gate_proj/MatMul ...
2025-02-08 02:08:31,131 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/mlp/gate_proj/MatMul ...
2025-02-08 02:08:31,131 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/mlp/up_proj/MatMul ...
2025-02-08 02:08:31,269 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/mlp/up_proj/MatMul ...
2025-02-08 02:08:31,269 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.19/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:31,269 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.19/mlp/act_fn/Mul ...
2025-02-08 02:08:31,269 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.19/mlp/Mul ...
2025-02-08 02:08:31,269 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/mlp/down_proj/MatMul ...
2025-02-08 02:08:31,368 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/mlp/down_proj/MatMul ...
2025-02-08 02:08:31,369 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.20/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:31,369 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/attn/qkv_proj/MatMul ...
2025-02-08 02:08:31,477 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/attn/qkv_proj/MatMul ...
2025-02-08 02:08:31,478 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.20/attn/GroupQueryAttention ...
2025-02-08 02:08:31,478 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/attn/o_proj/MatMul ...
2025-02-08 02:08:31,515 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/attn/o_proj/MatMul ...
2025-02-08 02:08:31,516 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.20/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:31,516 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/mlp/gate_proj/MatMul ...
2025-02-08 02:08:31,651 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/mlp/gate_proj/MatMul ...
2025-02-08 02:08:31,651 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/mlp/up_proj/MatMul ...
2025-02-08 02:08:31,796 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/mlp/up_proj/MatMul ...
2025-02-08 02:08:31,796 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.20/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:31,796 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.20/mlp/act_fn/Mul ...
2025-02-08 02:08:31,796 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.20/mlp/Mul ...
2025-02-08 02:08:31,796 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/mlp/down_proj/MatMul ...
2025-02-08 02:08:31,909 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/mlp/down_proj/MatMul ...
2025-02-08 02:08:31,909 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.21/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:31,909 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/attn/qkv_proj/MatMul ...
2025-02-08 02:08:32,033 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/attn/qkv_proj/MatMul ...
2025-02-08 02:08:32,034 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.21/attn/GroupQueryAttention ...
2025-02-08 02:08:32,034 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/attn/o_proj/MatMul ...
2025-02-08 02:08:32,076 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/attn/o_proj/MatMul ...
2025-02-08 02:08:32,076 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.21/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:32,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/mlp/gate_proj/MatMul ...
2025-02-08 02:08:32,227 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/mlp/gate_proj/MatMul ...
2025-02-08 02:08:32,227 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/mlp/up_proj/MatMul ...
2025-02-08 02:08:32,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/mlp/up_proj/MatMul ...
2025-02-08 02:08:32,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.21/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:32,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.21/mlp/act_fn/Mul ...
2025-02-08 02:08:32,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.21/mlp/Mul ...
2025-02-08 02:08:32,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/mlp/down_proj/MatMul ...
2025-02-08 02:08:32,455 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/mlp/down_proj/MatMul ...
2025-02-08 02:08:32,456 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.22/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:32,456 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/attn/qkv_proj/MatMul ...
2025-02-08 02:08:32,571 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/attn/qkv_proj/MatMul ...
2025-02-08 02:08:32,571 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.22/attn/GroupQueryAttention ...
2025-02-08 02:08:32,571 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/attn/o_proj/MatMul ...
2025-02-08 02:08:32,615 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/attn/o_proj/MatMul ...
2025-02-08 02:08:32,615 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.22/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:32,615 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/mlp/gate_proj/MatMul ...
2025-02-08 02:08:32,758 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/mlp/gate_proj/MatMul ...
2025-02-08 02:08:32,758 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/mlp/up_proj/MatMul ...
2025-02-08 02:08:32,895 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/mlp/up_proj/MatMul ...
2025-02-08 02:08:32,895 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.22/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:32,895 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.22/mlp/act_fn/Mul ...
2025-02-08 02:08:32,895 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.22/mlp/Mul ...
2025-02-08 02:08:32,895 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/mlp/down_proj/MatMul ...
2025-02-08 02:08:33,002 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/mlp/down_proj/MatMul ...
2025-02-08 02:08:33,003 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.23/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:33,003 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/attn/qkv_proj/MatMul ...
2025-02-08 02:08:33,116 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/attn/qkv_proj/MatMul ...
2025-02-08 02:08:33,116 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.23/attn/GroupQueryAttention ...
2025-02-08 02:08:33,116 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/attn/o_proj/MatMul ...
2025-02-08 02:08:33,152 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/attn/o_proj/MatMul ...
2025-02-08 02:08:33,153 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.23/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:33,153 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/mlp/gate_proj/MatMul ...
2025-02-08 02:08:33,286 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/mlp/gate_proj/MatMul ...
2025-02-08 02:08:33,287 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/mlp/up_proj/MatMul ...
2025-02-08 02:08:33,443 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/mlp/up_proj/MatMul ...
2025-02-08 02:08:33,444 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.23/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:33,444 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.23/mlp/act_fn/Mul ...
2025-02-08 02:08:33,444 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.23/mlp/Mul ...
2025-02-08 02:08:33,444 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/mlp/down_proj/MatMul ...
2025-02-08 02:08:33,558 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/mlp/down_proj/MatMul ...
2025-02-08 02:08:33,558 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.24/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:33,558 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/attn/qkv_proj/MatMul ...
2025-02-08 02:08:33,687 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/attn/qkv_proj/MatMul ...
2025-02-08 02:08:33,687 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.24/attn/GroupQueryAttention ...
2025-02-08 02:08:33,687 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/attn/o_proj/MatMul ...
2025-02-08 02:08:33,733 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/attn/o_proj/MatMul ...
2025-02-08 02:08:33,733 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.24/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:33,733 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/mlp/gate_proj/MatMul ...
2025-02-08 02:08:33,864 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/mlp/gate_proj/MatMul ...
2025-02-08 02:08:33,864 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/mlp/up_proj/MatMul ...
2025-02-08 02:08:34,000 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/mlp/up_proj/MatMul ...
2025-02-08 02:08:34,000 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.24/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:34,000 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.24/mlp/act_fn/Mul ...
2025-02-08 02:08:34,000 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.24/mlp/Mul ...
2025-02-08 02:08:34,000 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/mlp/down_proj/MatMul ...
2025-02-08 02:08:34,102 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/mlp/down_proj/MatMul ...
2025-02-08 02:08:34,102 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.25/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:34,103 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/attn/qkv_proj/MatMul ...
2025-02-08 02:08:34,236 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/attn/qkv_proj/MatMul ...
2025-02-08 02:08:34,236 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.25/attn/GroupQueryAttention ...
2025-02-08 02:08:34,236 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/attn/o_proj/MatMul ...
2025-02-08 02:08:34,277 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/attn/o_proj/MatMul ...
2025-02-08 02:08:34,277 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.25/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:34,277 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/mlp/gate_proj/MatMul ...
2025-02-08 02:08:34,417 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/mlp/gate_proj/MatMul ...
2025-02-08 02:08:34,417 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/mlp/up_proj/MatMul ...
2025-02-08 02:08:34,558 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/mlp/up_proj/MatMul ...
2025-02-08 02:08:34,559 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.25/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:34,559 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.25/mlp/act_fn/Mul ...
2025-02-08 02:08:34,559 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.25/mlp/Mul ...
2025-02-08 02:08:34,559 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/mlp/down_proj/MatMul ...
2025-02-08 02:08:34,689 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/mlp/down_proj/MatMul ...
2025-02-08 02:08:34,690 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.26/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:34,690 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/attn/qkv_proj/MatMul ...
2025-02-08 02:08:34,824 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/attn/qkv_proj/MatMul ...
2025-02-08 02:08:34,824 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.26/attn/GroupQueryAttention ...
2025-02-08 02:08:34,825 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/attn/o_proj/MatMul ...
2025-02-08 02:08:34,861 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/attn/o_proj/MatMul ...
2025-02-08 02:08:34,861 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.26/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:34,861 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/mlp/gate_proj/MatMul ...
2025-02-08 02:08:35,011 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/mlp/gate_proj/MatMul ...
2025-02-08 02:08:35,012 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/mlp/up_proj/MatMul ...
2025-02-08 02:08:35,159 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/mlp/up_proj/MatMul ...
2025-02-08 02:08:35,159 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.26/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:35,159 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.26/mlp/act_fn/Mul ...
2025-02-08 02:08:35,160 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.26/mlp/Mul ...
2025-02-08 02:08:35,160 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/mlp/down_proj/MatMul ...
2025-02-08 02:08:35,277 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/mlp/down_proj/MatMul ...
2025-02-08 02:08:35,277 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.27/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:35,277 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/attn/qkv_proj/MatMul ...
2025-02-08 02:08:35,411 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/attn/qkv_proj/MatMul ...
2025-02-08 02:08:35,411 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.27/attn/GroupQueryAttention ...
2025-02-08 02:08:35,411 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/attn/o_proj/MatMul ...
2025-02-08 02:08:35,454 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/attn/o_proj/MatMul ...
2025-02-08 02:08:35,454 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.27/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:35,455 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/mlp/gate_proj/MatMul ...
2025-02-08 02:08:35,619 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/mlp/gate_proj/MatMul ...
2025-02-08 02:08:35,619 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/mlp/up_proj/MatMul ...
2025-02-08 02:08:35,785 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/mlp/up_proj/MatMul ...
2025-02-08 02:08:35,785 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.27/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:35,785 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.27/mlp/act_fn/Mul ...
2025-02-08 02:08:35,786 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.27/mlp/Mul ...
2025-02-08 02:08:35,786 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/mlp/down_proj/MatMul ...
2025-02-08 02:08:35,907 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/mlp/down_proj/MatMul ...
2025-02-08 02:08:35,907 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.28/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:35,907 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/attn/qkv_proj/MatMul ...
2025-02-08 02:08:36,027 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/attn/qkv_proj/MatMul ...
2025-02-08 02:08:36,028 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.28/attn/GroupQueryAttention ...
2025-02-08 02:08:36,028 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/attn/o_proj/MatMul ...
2025-02-08 02:08:36,067 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/attn/o_proj/MatMul ...
2025-02-08 02:08:36,067 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.28/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:36,067 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/mlp/gate_proj/MatMul ...
2025-02-08 02:08:36,196 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/mlp/gate_proj/MatMul ...
2025-02-08 02:08:36,196 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/mlp/up_proj/MatMul ...
2025-02-08 02:08:36,331 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/mlp/up_proj/MatMul ...
2025-02-08 02:08:36,331 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.28/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:36,331 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.28/mlp/act_fn/Mul ...
2025-02-08 02:08:36,332 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.28/mlp/Mul ...
2025-02-08 02:08:36,332 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/mlp/down_proj/MatMul ...
2025-02-08 02:08:36,437 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/mlp/down_proj/MatMul ...
2025-02-08 02:08:36,437 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.29/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:36,438 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/attn/qkv_proj/MatMul ...
2025-02-08 02:08:36,573 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/attn/qkv_proj/MatMul ...
2025-02-08 02:08:36,573 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.29/attn/GroupQueryAttention ...
2025-02-08 02:08:36,573 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/attn/o_proj/MatMul ...
2025-02-08 02:08:36,618 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/attn/o_proj/MatMul ...
2025-02-08 02:08:36,619 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.29/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:36,619 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/mlp/gate_proj/MatMul ...
2025-02-08 02:08:36,783 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/mlp/gate_proj/MatMul ...
2025-02-08 02:08:36,783 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/mlp/up_proj/MatMul ...
2025-02-08 02:08:36,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/mlp/up_proj/MatMul ...
2025-02-08 02:08:36,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.29/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:36,953 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.29/mlp/act_fn/Mul ...
2025-02-08 02:08:36,954 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.29/mlp/Mul ...
2025-02-08 02:08:36,954 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/mlp/down_proj/MatMul ...
2025-02-08 02:08:37,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/mlp/down_proj/MatMul ...
2025-02-08 02:08:37,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.30/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:37,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/attn/qkv_proj/MatMul ...
2025-02-08 02:08:37,207 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/attn/qkv_proj/MatMul ...
2025-02-08 02:08:37,207 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.30/attn/GroupQueryAttention ...
2025-02-08 02:08:37,207 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/attn/o_proj/MatMul ...
2025-02-08 02:08:37,245 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/attn/o_proj/MatMul ...
2025-02-08 02:08:37,245 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.30/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:37,245 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/mlp/gate_proj/MatMul ...
2025-02-08 02:08:37,382 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/mlp/gate_proj/MatMul ...
2025-02-08 02:08:37,382 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/mlp/up_proj/MatMul ...
2025-02-08 02:08:37,531 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/mlp/up_proj/MatMul ...
2025-02-08 02:08:37,531 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.30/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:37,531 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.30/mlp/act_fn/Mul ...
2025-02-08 02:08:37,531 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.30/mlp/Mul ...
2025-02-08 02:08:37,532 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/mlp/down_proj/MatMul ...
2025-02-08 02:08:37,658 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/mlp/down_proj/MatMul ...
2025-02-08 02:08:37,658 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.31/input_layernorm/SkipLayerNorm ...
2025-02-08 02:08:37,658 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/attn/qkv_proj/MatMul ...
2025-02-08 02:08:37,803 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/attn/qkv_proj/MatMul ...
2025-02-08 02:08:37,804 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.31/attn/GroupQueryAttention ...
2025-02-08 02:08:37,804 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/attn/o_proj/MatMul ...
2025-02-08 02:08:37,848 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/attn/o_proj/MatMul ...
2025-02-08 02:08:37,849 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.31/post_attention_layernorm/SkipLayerNorm ...
2025-02-08 02:08:37,849 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/mlp/gate_proj/MatMul ...
2025-02-08 02:08:38,018 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/mlp/gate_proj/MatMul ...
2025-02-08 02:08:38,018 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/mlp/up_proj/MatMul ...
2025-02-08 02:08:38,194 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/mlp/up_proj/MatMul ...
2025-02-08 02:08:38,194 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.31/mlp/act_fn/Sigmoid ...
2025-02-08 02:08:38,194 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.31/mlp/act_fn/Mul ...
2025-02-08 02:08:38,195 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.31/mlp/Mul ...
2025-02-08 02:08:38,195 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/mlp/down_proj/MatMul ...
2025-02-08 02:08:38,321 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/mlp/down_proj/MatMul ...
2025-02-08 02:08:38,322 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - skip to quantize /model/layers.32/final_norm_layernorm/SkipLayerNorm ...
2025-02-08 02:08:38,322 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /lm_head/MatMul ...
2025-02-08 02:08:38,891 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /lm_head/MatMul ...
Saving GenAI config in e:\llama.cpp\models\Phi-3\onnx\gguf_onnx
tokenizer_config.json: 100%|| 3.44k/3.44k [00:00<?, ?B/s]
e:\xCloud_Reuse\python312\Lib\site-packages\huggingface_hub\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\llama.cpp\models\Phi-3\microsoft-Phi-3\models--microsoft--phi-3-mini-4k-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
tokenizer.model: 100%|| 500k/500k [00:00<00:00, 22.5MB/s]
tokenizer.json: 100%|| 1.94M/1.94M [00:00<00:00, 23.8MB/s]
added_tokens.json: 100%|| 306/306 [00:00<?, ?B/s]
special_tokens_map.json: 100%|| 599/599 [00:00<?, ?B/s]
Saving processing files in e:\llama.cpp\models\Phi-3\onnx\gguf_onnx for GenAI